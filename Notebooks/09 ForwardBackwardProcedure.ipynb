{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, planteamos una forma eficiente de programar el procedimiento de avance a partir de operaciones con arreglos de numpy. En primer lugar, llamamos a la librería de numpy, la cual utilizaremos para crear y operar con los arreglos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supóngamos que tenemos un Modelo Oculto de Markov $HMM = (O,S,A,B,\\Pi)$, donde el alfabeto de emisiones se define por:\n",
    "\n",
    "$$S = \\{D, NN, V\\}$$\n",
    "\n",
    "Y el alfabeto de observaciones está determinado como: \n",
    "\n",
    "$$O = \\{la, niña, garza, pasa\\}$$\n",
    "\n",
    "Para determinar estos símbolos, indexaremos los elementos de cada alfabeto a partir de dictionarios (en este caso hace falta únicamente indexar el alfabeto $\\Sigma$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = {'la': 0, 'nina': 1, 'garza':2, 'pasa':3}\n",
    "S = {0:'DA', 1:'N', 2:'V'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las probabilidades se pueden determinar de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.array([4/6, 1/6, 1/6])\n",
    "A = np.array([[1/6,1/6,1/5],[4/6,1/6,1/5],[1/6,3/6,1/5]])\n",
    "B = np.array([[4/7,1/7,1/6],[1/7,2/7,1/6],[1/7,2/7,1/6],[1/7,2/7,3/6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas probabilidades, junto con los alfabetos de observaciones y emisiones nos dan el Modelo Oculto de Markov $HMM$. Ahora supongamos que queremos determinar la probabilidad de una cadena de observaciones $d\\in\\Delta^*$, definida como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'nina', 'pasa', 'la', 'garza']\n"
     ]
    }
   ],
   "source": [
    "obs = 'la nina pasa la garza'\n",
    "obs = obs.split()\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos el procedimiento de avance para determinar dicha probabilidad. Realizaremos los pasos de inicialización, inducción y terminación (en cada paso, guardamos las variables en una matriz):\n",
    "\n",
    "(1) Inicialización. La inicialización está dada por el almacenamiento de las probabilidades inciiales en la variable de avance:\n",
    "\n",
    "$$\\alpha_i(0) := \\pi_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((len(obs)+1,len(Pi)))\n",
    "a[0] = Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Inducción. Los siguientes pasos consistirán en ir actualizando la variable de avance a partir de los diferentes estados de la cadena:\n",
    "\n",
    "$$\\alpha_i(t+1) =  p(o_t|s_i)\\sum_{j=1}^N p(s_i|s_j)\\alpha_j(t)$$\n",
    "\n",
    "En este caso, utilizaremos operaciones entre matrices y vectores, pues es evidente que (tomando los elementos del modelo $A,B,\\Pi$):\n",
    "\n",
    "$$\\alpha_i(t+1) = B_{t,\\cdot} \\odot (A_{i,\\cdot} \\alpha_{\\cdot}(t))$$\n",
    "\n",
    "donde $B_{t,\\cdot}$ representa el vector renglón que corresponde a la observación en el estado $t$ y  $\\alpha_{\\cdot}(t)$ es el vector que contiene todas las variables $\\alpha_i(t)$. Aquí, $A_{i,\\cdot}$ representa el i-ésimo vector renglón de $A$ y $\\odot$ representa el producto de Hadamard. En general, podemos actualizar todo el vector $\\alpha(t+1)$ (cuyas entradas son $\\alpha_i(t+1)$) tomando la matriz completa $A$. De tal forma que:\n",
    "\n",
    "$$\\alpha(t+1) = B_{t,\\cdot} \\odot (A \\alpha_{\\cdot}(t)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simbolo: la - probabilidad 0.20859788359788356\n",
      "simbolo: la nina - probabilidad 0.03951877047115142\n",
      "simbolo: la nina pasa - probabilidad 0.011220368570708704\n",
      "simbolo: la nina pasa la - probabilidad 0.0020895512786453284\n",
      "simbolo: la nina pasa la garza - probabilidad 0.00041117213569291135\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(obs)):\n",
    "    a[t+1] =  B[ O[obs[t]] ] * np.dot(A,a[t])\n",
    "    print('simbolo:', (' ').join(obs[:t+1]), '- probabilidad',a[t+1].sum(0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Terminación. Para la terminación, tenemos que:\n",
    "\n",
    "$$p(o^{(1)}...o^{(T)}) = \\sum_{i=1}^N \\alpha_i(T)$$\n",
    "\n",
    "Pero ya que hemos guardado cada variable $\\alpha_i$ como la entrada de un vector, basta sumar las entradas de este vector para obtener esta probabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de la cadena ['la', 'nina', 'pasa', 'la', 'garza'] es: 0.00041117213569291135\n"
     ]
    }
   ],
   "source": [
    "print('Probabilidad de la cadena',obs, 'es:', a[len(obs)].sum(0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Procedure\n",
    "\n",
    "El procedimiento de retroceso o bacward procedure es similar al procedimiento de avance, pero la cadena se recorre en sentido inverso, es decir, de derecha a izquierda. Aquí presentamos una implementación simplie de este procedimiento utilizando las propiedades de operaciones entre arreglos en numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es cuando iniciamos con el procedimiento de retroceso. El paso de inducción consiste en determinar las variables $\\beta_i(T) = 1$. En este caso, utilizamos un vector, que podemos denotar como $\\beta_\\cdot(T)$, el cual contendrá en un primer momento sólo unos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.zeros((len(obs)+1,len(Pi)))\n",
    "b[len(obs)] = np.ones(len(Pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el paso inductivo tenemos que obtener las variables:\n",
    "\n",
    "$$\\beta_j(t) = \\sum_{i=1}^N p(o^{(t+1)} | s_i^{(t+1)}) p(s_i^{(t+1)}|s_{j}^{(t)}) \\beta_i(t+1)$$\n",
    "\n",
    "Ya que estamos trabajando con arreglos de numpy, podemos ver que la suma y el producto sobre los $i$-ésimos elementos determinan un producto punto. Así, $B_{(t+1),\\cdot}$ representa el vector columna correspondiente al elemento de la cadena de observaciones en el estado $t+1$, $A_{\\cdot, j}$ a la $j$-ésima columna de la matriz de transiciones $A$ y $\\hat{\\beta}(t+1)$ al vector de las variables $\\beta$ en el estado subsecuente. Así, podemos expresar la ecuación anterior como:\n",
    "\n",
    "$$\\beta_j(t) = [\\hat{\\beta}(t+1) \\odot B_{(t+1),\\cdot}] \\cdot A_{\\cdot, j}$$\n",
    "\n",
    "Donde $\\cdot$ es el producto punto, y $\\odot$ el producto de Hadarmard. En términos generales, podemos actualizar todas las variables $\\beta$ expresándolo como un vector $\\hat{\\beta}(t)$ y de esta forma, tenemos que realizar la operación:\n",
    "\n",
    "$$\\hat{\\beta(t)} = A^T [\\hat{\\beta}(t+1) \\odot B_{(t+1),\\cdot}]$$\n",
    "\n",
    "Donde el producto punto se hace con toda la matriz de transiciones $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simbolo: garza - probabilidad: 0.20701058201058198\n",
      "simbolo: la garza - probabilidad: 0.03951877047115142\n",
      "simbolo: pasa la garza - probabilidad: 0.010412587433562487\n",
      "simbolo: nina pasa la garza - probabilidad: 0.002226236896034973\n",
      "simbolo: la nina pasa la garza - probabilidad: 0.0004111721356929113\n"
     ]
    }
   ],
   "source": [
    "T = len(obs)\n",
    "for i in range(T):    \n",
    "    t = (T-(i+1))\n",
    "    b[t] = np.dot(A.T, b[t+1]*B[O[obs[t]]])    \n",
    "       \n",
    "    print('simbolo:', (' ').join(obs[t:]), '- probabilidad:', np.dot(Pi,b[t]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, el paso de terminación consiste en obtener la probabilidad de la cadena de la siguiente forma:\n",
    "\n",
    "$$p(o^{(1)}...o^{(T)}) = \\sum_{j=1}^N  \\pi_j \\beta_j(0)$$\n",
    "\n",
    "Donde $\\pi_j$ es la $j$-ésima probabilidad inicial. De igual forma, podemos aprovechar la estructura de los arreglos y expresar la suma de los productos por medio de un producto punto con el vector de probabilidades inicailes $\\Pi$ y el vector de variables $\\beta(0)$. Esto es:\n",
    "\n",
    "$$p(o^{(1)}...o^{(T)}) =  \\Pi \\cdot \\hat{\\beta}(0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilidad de la observación es: 0.0004111721356929113\n"
     ]
    }
   ],
   "source": [
    "print('La probabilidad de la observación es:', np.dot(Pi,b[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward-Bacward Procedure\n",
    "\n",
    "El procedimiento de avance-retroceso puede usarse para calcular la probabilidad de una cadena; en particular, tenemos que:\n",
    "\n",
    "$$p(o^{(1)}...o^{(T)}) = \\sum_{i=1}^N \\alpha_i(t) \\beta_i(t)$$\n",
    "\n",
    "En este sentido para cada $t$ (de $1$ a $T$) podremos utilizar las variables en ese estado para calcular la probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilidad en estado t de \"la nina pasa la garza\" es [0.00041117 0.00041117 0.00041117 0.00041117 0.00041117 0.00041117]\n"
     ]
    }
   ],
   "source": [
    "prob = (a*b).sum(1)\n",
    "\n",
    "print('La probabilidad en estado t de \"{}\" es {}'.format(' '.join(obs), prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El avnace-retroceso nos da la probabilidad conjunta de la cadena y el símbolo en un estado $t$:\n",
    "\n",
    "$$p(o^{(1)}...o^{(T)}, s_i^{(t)}) = \\alpha_i(t) \\beta_i(t)$$\n",
    "\n",
    "Más aún, también nos puede dar las probabilidades condicionales de la siguiente forma:\n",
    "\n",
    "$$p(s_i^{(t)}|o^{(1)}...o^{(T)}) = \\frac{\\alpha_i(t) \\beta_i(t)}{\\sum_i \\alpha_i(t) \\beta_i(t)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DA</th>\n",
       "      <th>N</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BOS</th>\n",
       "      <td>0.684777</td>\n",
       "      <td>0.158185</td>\n",
       "      <td>0.157038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>0.643323</td>\n",
       "      <td>0.244665</td>\n",
       "      <td>0.112012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nina</th>\n",
       "      <td>0.137279</td>\n",
       "      <td>0.695233</td>\n",
       "      <td>0.167488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasa</th>\n",
       "      <td>0.098821</td>\n",
       "      <td>0.241848</td>\n",
       "      <td>0.659331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>0.713422</td>\n",
       "      <td>0.140610</td>\n",
       "      <td>0.145968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garza</th>\n",
       "      <td>0.126837</td>\n",
       "      <td>0.674711</td>\n",
       "      <td>0.198452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DA         N         V\n",
       "BOS    0.684777  0.158185  0.157038\n",
       "la     0.643323  0.244665  0.112012\n",
       "nina   0.137279  0.695233  0.167488\n",
       "pasa   0.098821  0.241848  0.659331\n",
       "la     0.713422  0.140610  0.145968\n",
       "garza  0.126837  0.674711  0.198452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probabilidad condicional\n",
    "pd.DataFrame(data=(a*b)/prob[0], columns=list(S.values()), index=['BOS']+obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces predecir la probabilidad de una etiqueta y obtener la etiqueta adecuada para cada estado de la cadena de observaciones. La predicicón se hace como:\n",
    "\n",
    "\\begin{align}\n",
    "    \\hat{s}^{(t)} &= \\arg\\max_i p(s_i^{(t)}|o^{(1)}...o^{(T)}) = \\arg\\max_i \\frac{\\alpha_i(t) \\beta_i(t)}{\\sum_i \\alpha_i(t) \\beta_i(t)} \\\\\n",
    "                &= \\arg\\max_i p(o^{(1)}...o^{(T)}, s_i^{(t)}) = \\arg\\max_i \\alpha_i(t) \\beta_i(t)\n",
    "\\end{align}\n",
    "\n",
    "Como ya hemos guardado las variables $\\alpha$ y $\\beta$ basta multiplicarlas y obtener el argumento que maximiza el producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('la', 'DA'), ('nina', 'N'), ('pasa', 'V'), ('la', 'DA'), ('garza', 'N')]\n"
     ]
    }
   ],
   "source": [
    "#Predicción en base a forward-backward\n",
    "pred = [S[t] for t in np.argmax(a*b, axis=1)]\n",
    "#Obtención de la secuencia etiquetada\n",
    "tag_obs = list(zip(obs,pred[1:]))\n",
    "\n",
    "print(tag_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
