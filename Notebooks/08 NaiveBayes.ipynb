{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4094e1c5",
   "metadata": {},
   "source": [
    "# Algoritmo Naïve Bayes\n",
    "\n",
    "Presentamos una implementación del algoritmo de Bayes naïve (o ingenuo) para un problema particular que la clasificación de texto en lenguas a partir de la frecuencia de los conjuntos de caracteres que en ellos se presentan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a07123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown, cess_esp\n",
    "from nltk import ngrams\n",
    "from elotl.corpus import load\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter, defaultdict\n",
    "from re import sub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992fb76",
   "metadata": {},
   "source": [
    "### Preparación de los datos\n",
    "\n",
    "En primer lugar, obtenemos los datos con los que vamos a trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743411f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos a usar en inglés, español, otomí y náhua\n",
    "eng = brown.sents()\n",
    "esp = cess_esp.sents()\n",
    "oto = [sent[1].split() for sent in load('tsunkua')]\n",
    "nah = [sent[1].split() for sent in load('axolotl')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab2056",
   "metadata": {},
   "source": [
    "Para hacer la clasificaicón usaremos conjuntos de caracteres (n-gramas); es decir, un texto se clasificará en una lengua según los patrones de caracteres que contenga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906675a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(word,n):\n",
    "    \"\"\"\n",
    "    Función para obtener n-gramas.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    word : str\n",
    "        Palabra que se va a separar en patrones de caracteres o n-gramas.\n",
    "    n : int\n",
    "        Tamaño de n-grama\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Lista de n-gramas de la cadena.\n",
    "    \"\"\"\n",
    "    #Limpia el texto\n",
    "    clean_word = sub('[^\\w\\s)]','',word.lower())        \n",
    "    if len(clean_word) <= n and clean_word != '':\n",
    "        #Si no se peuden obtener n-gramas\n",
    "        ngram_list = [clean_word]\n",
    "    else:\n",
    "        #Obtiene n-gramas\n",
    "        ngram_list = [''.join(ngram) for ngram in  ngrams(clean_word,n)]\n",
    "    \n",
    "    return ngram_list\n",
    "\n",
    "def process(sent, n=2):\n",
    "    \"\"\"\n",
    "    Función para procesar las oraciones de un texto.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    sent : list[str]\n",
    "        Lista de palabras que componen una oración del texto\n",
    "    n : int\n",
    "        Tamaño de n-grama\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Lista de n-gramas de la oración\n",
    "    \"\"\"\n",
    "    sent_ngrams = list(chain(*[get_ngrams(w,n) for w in sent]))\n",
    "    \n",
    "    return sent_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9767ca8",
   "metadata": {},
   "source": [
    "Podemos observar qué tipo de procesamiento es el que se hace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8a9ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'el', 'qu', 'ue', 'de', 'el', 'ni', 'iñ', 'ño', 'de', 'aq', 'qu', 'uí']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = 'y el ¿que del niño de aquí?.'.split()\n",
    "print(process(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f072ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    \"\"\"\n",
    "    Clase para crear el dataset de las lenguas.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Values\n",
    "        ------\n",
    "        self.language\n",
    "            Diccionario de lenguas y sus correspondientes textos.\n",
    "        self.X\n",
    "            Datos de entrada\n",
    "        self.Y\n",
    "            Clases de salida\n",
    "        \"\"\"\n",
    "        self.languages = {'english': eng,'spanish':esp,'nahuatl':nah,'otomi':oto}\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        \"\"\"\n",
    "        Función para crear el dataset (pares [x,y]) a partir de los textos.\n",
    "        \"\"\"\n",
    "        for lang, sentences in self.languages.items():\n",
    "            print(lang)\n",
    "            for sent in sentences:\n",
    "                #Procesa los textos\n",
    "                x = process(sent)\n",
    "\n",
    "                #Genera los inputs y las clases\n",
    "                self.X.append(x)\n",
    "                self.Y.append(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4990e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english\n",
      "spanish\n",
      "nahuatl\n",
      "otomi\n"
     ]
    }
   ],
   "source": [
    "#Creamos el dataset\n",
    "dataset = Dataset()\n",
    "dataset.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d756c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84450 84450\n"
     ]
    }
   ],
   "source": [
    "#Imprime longitud del dataset\n",
    "print(len(dataset.X), len(dataset.Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844011a",
   "metadata": {},
   "source": [
    "Creamos el conjunto de entrenamiento y de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1e2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset.X, dataset.Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a1093",
   "metadata": {},
   "source": [
    "## Modelo de Naïve Bayes\n",
    "\n",
    "Ahora definimos el modelo de Naïve Bayes con el cual podremos realizar la clasificación que esperamos. Este modelo guarda las probabilidades de la forma: $p(x|y)$ y $p(y)$; estos pueden pensarse como los parámetros del modelo a partir de los cuáles se puede estimar la probabilidad:\n",
    "\n",
    "$$p(y,x) = \\prod_i p(x_i|y)p(y)$$\n",
    "\n",
    "Y la clase se obtiene como $\\hat{y} = \\arg\\max_y p(y,x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7c1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    \"\"\"\n",
    "    Clase del modelo de bayes ingenuo.\n",
    "    \"\"\"\n",
    "    def __init__(self, priors={}):\n",
    "        \"\"\"\n",
    "        Values\n",
    "        ------\n",
    "        self.prec_prior \n",
    "            Valores de probabilidad prior si es que se dan.\n",
    "        self.priors\n",
    "            Priors del modelo\n",
    "        self.categories\n",
    "            Categorias o clases del modelo.\n",
    "        self.conditional\n",
    "            Probabilidades de la forma p(x|y) para los rasgos.\n",
    "            \n",
    "        Arguments\n",
    "        ---------\n",
    "        priors : dict\n",
    "            Dictionario de probabilidades a priori para cada clase, \n",
    "            si no se presenta, las prior se calculan de los ejemplos.\n",
    "        \"\"\"\n",
    "        self.prec_priors = priors\n",
    "        self.priors = {}\n",
    "        categories = []\n",
    "        self.conditional = {}\n",
    "    \n",
    "    def count_cat(self, y):\n",
    "        \"\"\"\n",
    "        Función para contar las clases.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        y : list\n",
    "            Lista de clases para cada uno de los ejemplos.\n",
    "        \"\"\"\n",
    "        freqs = Counter(y)\n",
    "        total_freq = sum(freqs.values())\n",
    "        for lang, freq in freqs.items():\n",
    "            self.priors[lang] = freq/total_freq\n",
    "            \n",
    "    def count_cond(self,x,y):\n",
    "        \"\"\"\n",
    "        Función para contar las probabilidades condicionales p(x|y)\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x, y : list\n",
    "            Lista de ejemplos de entrenamiento asociados a sus clases\n",
    "        \"\"\"\n",
    "        freq_cat = Counter(y)\n",
    "        print(freq_cat)\n",
    "        joint_elements = defaultdict(list)\n",
    "        for category,example in zip(y,x):\n",
    "            joint_elements[category].append(example)\n",
    "        \n",
    "        for category,examples in joint_elements.items():\n",
    "            freqs = Counter(chain(*examples))\n",
    "            total_freq = sum(freqs.values())\n",
    "            self.conditional[category] = {w:freq/total_freq for w,freq in freqs.items()}\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        \"\"\"\n",
    "        Función para entrenar el modelo.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x, y : list\n",
    "            Lista de ejemplos de entrenamiento asociados a sus clases\n",
    "        \"\"\"\n",
    "        if self.prec_priors == {}:\n",
    "            self.count_cat(y)\n",
    "        else:\n",
    "            for i,category in enumerate(set(y)):\n",
    "                self.priors[category] = self.prec_priors[i]\n",
    "        \n",
    "        self.categories = list(self.priors.keys())\n",
    "        self.count_cond(x,y)\n",
    "        \n",
    "    def predict_proba(self,x):\n",
    "        \"\"\"\n",
    "        Función para obtener probabilidades de clases.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : list\n",
    "            Lista de ejemplos para predicción.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            Probabilidad de las clases.\n",
    "        \"\"\"\n",
    "        prediction = np.zeros(len(self.priors))\n",
    "        for i,category in enumerate(self.categories):\n",
    "            p = 1\n",
    "            prior = self.priors[category]\n",
    "            for x_i in x:\n",
    "                try:\n",
    "                    cond = self.conditional[category][x_i]\n",
    "                except:\n",
    "                    cond = 1/prior\n",
    "                p *= cond*prior\n",
    "                \n",
    "            prediction[i] = p\n",
    "            \n",
    "        return prediction\n",
    "    \n",
    "    def predict_logproba(self,x):\n",
    "        \"\"\"\n",
    "        Función para obtener logaritmos de probabilidades de clases.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : list\n",
    "            Lista de ejemplos para predicción.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            Logaritmo de la probabilidad de las clases.\n",
    "        \"\"\"\n",
    "        prediction = np.zeros(len(self.priors))\n",
    "        for i,category in enumerate(self.categories):\n",
    "            p = 0\n",
    "            prior = self.priors[category]\n",
    "            for x_i in x:\n",
    "                try:\n",
    "                    cond = self.conditional[category][x_i]\n",
    "                except:\n",
    "                    cond = 1/prior\n",
    "                \n",
    "                p += np.log(cond*prior)\n",
    "                \n",
    "            prediction[i] = p\n",
    "            \n",
    "        return prediction\n",
    "        \n",
    "    def predict(self,x,log=True):\n",
    "        \"\"\"\n",
    "        Función para predecir las clases de un ejemplo de evaluación.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        x : list\n",
    "            Lista de ejemplos para predicción.\n",
    "        log : bool\n",
    "            Indica si se obtienen las clases desde el logaritmo de la probabilidad\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            Clase de mayor probabilidad.\n",
    "        \"\"\"\n",
    "        if log:\n",
    "            probas = self.predict_logproba(x)\n",
    "        else:\n",
    "            probas = self.predict_proba(x)\n",
    "        y_hat = np.argmax(probas)\n",
    "        \n",
    "        return self.categories[y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0b1df",
   "metadata": {},
   "source": [
    "Construimos el modelo en base a unos prios uniformes y lo entrenamos con nuestros datos de entrenamiento que hemos obtenido anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f696837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'english': 40168, 'nahuatl': 11254, 'spanish': 4218, 'otomi': 3475})\n"
     ]
    }
   ],
   "source": [
    "#Modelo\n",
    "clf = NaiveBayesClassifier(priors=[0.25,0.25,0.25,0.25])\n",
    "#Entrenamiento\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aaf4bf",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Para evaluar el modelo, usamos el dataset de evaluación y predecimos las clases a las que pertenece. Calculamos métricas de evaluación para saber qué tan bien trabaja nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eaceb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     english       0.89      0.95      0.92     17172\n",
      "     nahuatl       0.97      0.88      0.92      4863\n",
      "       otomi       0.43      0.52      0.47      1488\n",
      "     spanish       0.63      0.35      0.45      1812\n",
      "\n",
      "    accuracy                           0.86     25335\n",
      "   macro avg       0.73      0.67      0.69     25335\n",
      "weighted avg       0.86      0.86      0.86     25335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [clf.predict(x) for x in x_test]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db58c3f",
   "metadata": {},
   "source": [
    "Podemos ver cómo trabaja en casos individuales de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2ea7555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spanish\n"
     ]
    }
   ],
   "source": [
    "#Texto de entrada\n",
    "input_text = 'el gobierno' #'ra detha' #'tinechmacasnequi'\n",
    "\n",
    "#Imprime la clase\n",
    "print(clf.predict(process(input_text.split()), log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e1ce5",
   "metadata": {},
   "source": [
    "Finalmente, podemos explorar cuáles son los rasgos que más influyen para la decisión en cada una de las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7dec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 0.02949939931099778),\n",
       " ('en', 0.024363707245661913),\n",
       " ('es', 0.022261295737892737),\n",
       " ('la', 0.01858157834018888),\n",
       " ('os', 0.017807843168455472),\n",
       " ('er', 0.016345901391529888),\n",
       " ('el', 0.01600975423465856),\n",
       " ('ar', 0.01519623833430133),\n",
       " ('ra', 0.014860091177430005),\n",
       " ('ue', 0.014846167922411667)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "sorted(clf.conditional['spanish'].items(),key=itemgetter(1),reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7877e282",
   "metadata": {},
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
